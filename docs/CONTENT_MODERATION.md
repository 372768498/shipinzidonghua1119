# å†…å®¹å®¡æŸ¥ç³»ç»Ÿæ–‡æ¡£

> **ç‰ˆæœ¬**: v2.0  
> **æœ€åæ›´æ–°**: 2024-11-19  
> **ç»´æŠ¤è€…**: Jilo.ai Security Team

---

## ğŸ“‹ ç›®å½•

- [ç³»ç»Ÿæ¦‚è¿°](#ç³»ç»Ÿæ¦‚è¿°)
- [ä¸‰å±‚é˜²æŠ¤æ¶æ„](#ä¸‰å±‚é˜²æŠ¤æ¶æ„)
- [æŠ€æœ¯å®ç°](#æŠ€æœ¯å®ç°)
- [å®¡æŸ¥è§„åˆ™](#å®¡æŸ¥è§„åˆ™)
- [ç”¨æˆ·ç›‘æ§](#ç”¨æˆ·ç›‘æ§)
- [APIé›†æˆ](#apié›†æˆ)
- [æµ‹è¯•ä¸éªŒè¯](#æµ‹è¯•ä¸éªŒè¯)

---

## ç³»ç»Ÿæ¦‚è¿°

### ä¸ºä»€ä¹ˆéœ€è¦å†…å®¹å®¡æŸ¥ï¼Ÿ

Jilo.aiæ˜¯å…¨è‡ªåŠ¨çš„è§†é¢‘ç”Ÿæˆå’Œå‘å¸ƒå¹³å°ï¼š

```
ç”¨æˆ·è¾“å…¥Prompt â†’ AIç”Ÿæˆè§†é¢‘ â†’ è‡ªåŠ¨å‘å¸ƒåˆ°YouTube
```

å¦‚æœæ²¡æœ‰å†…å®¹å®¡æŸ¥ï¼Œæ¶æ„ç”¨æˆ·å¯èƒ½ï¼š
- âŒ ç”Ÿæˆè¿è§„å†…å®¹ï¼ˆè‰²æƒ…ã€æš´åŠ›ã€ä»‡æ¨è¨€è®ºï¼‰
- âŒ åˆ›å»ºåäºº/æ”¿æ²»äººç‰©çš„Deepfake
- âŒ å‘å¸ƒè¯¯å¯¼æ€§è™šå‡ä¿¡æ¯
- âŒ ä¾µçŠ¯ç‰ˆæƒå†…å®¹

**åæœï¼š**
- ğŸš« FAL.AIè´¦å·è¢«å° â†’ ä¸šåŠ¡ä¸­æ–­
- ğŸš« Google Cloudé¡¹ç›®è¢«å° â†’ æ°¸ä¹…æŸå¤±
- âš–ï¸ æ³•å¾‹è´£ä»» â†’ å…¬å¸å€’é—­

### è®¾è®¡åŸåˆ™

1. **Fail-Closed**: å®¡æŸ¥å¤±è´¥æ—¶ï¼Œæ‹’ç»è¯·æ±‚è€Œéæ”¾è¡Œ
2. **å¤šå±‚é˜²æŠ¤**: é»‘åå• + AIå®¡æŸ¥ + ç”¨æˆ·ç›‘æ§
3. **å®æ—¶æ‹¦æˆª**: ç”Ÿæˆå‰æ‹¦æˆªï¼Œä¸æ˜¯ç”Ÿæˆååˆ é™¤
4. **å¯è¿½æº¯**: æ‰€æœ‰å®¡æŸ¥è®°å½•æ°¸ä¹…ä¿å­˜

---

## ä¸‰å±‚é˜²æŠ¤æ¶æ„

```
ç”¨æˆ·Prompt â†’ [ç¬¬ä¸€å±‚ï¼šé»‘åå•è¿‡æ»¤] â†’ [ç¬¬äºŒå±‚ï¼šAIå†…å®¹åˆ†æ] â†’ [ç¬¬ä¸‰å±‚ï¼šç”¨æˆ·é£é™©è¯„åˆ†] â†’ æ”¾è¡Œ/æ‹’ç»
```

### ç¬¬ä¸€å±‚ï¼šé»‘åå•è¿‡æ»¤ï¼ˆå®æ—¶ï¼Œ<10msï¼‰

**ç›®æ ‡**: å¿«é€Ÿæ‹¦æˆªæ˜æ˜¾è¿è§„çš„å…³é”®è¯

```typescript
// src/lib/moderation/blacklist.ts
export const BLACKLIST_CATEGORIES = {
  sexual: [
    'porn', 'è‰²æƒ…', 'nude', 'è£¸ä½“', 'sex', 'æ€§çˆ±',
    'adult content', 'æˆäººå†…å®¹', 'xxx'
  ],
  violence: [
    'kill', 'æ€äºº', 'murder', 'è°‹æ€', 'terrorist', 'ææ€–',
    'suicide', 'è‡ªæ€', 'torture', 'é…·åˆ‘'
  ],
  hate_speech: [
    'nazi', 'çº³ç²¹', 'racist', 'ç§æ—æ­§è§†', 'genocide', 'ç§æ—ç­ç»',
    'hate speech', 'ä»‡æ¨è¨€è®º'
  ],
  political: [
    'deepfake president', 'æ€»ç»Ÿæ·±åº¦ä¼ªé€ ',
    'fake news election', 'é€‰ä¸¾å‡æ–°é—»'
  ],
  celebrities: [
    'deepfake celebrity', 'æ˜æ˜Ÿæ·±åº¦ä¼ªé€ ',
    'fake celebrity video', 'å‡å†’åäººè§†é¢‘'
  ],
  illegal: [
    'drug', 'æ¯’å“', 'cocaine', 'å¯å¡å› ', 'weapon', 'æ­¦å™¨',
    'bomb', 'ç‚¸å¼¹', 'hack', 'é»‘å®¢æ”»å‡»'
  ]
}

export function checkBlacklist(prompt: string): {
  passed: boolean
  violations: string[]
  category: string | null
} {
  const lowerPrompt = prompt.toLowerCase()
  const violations: string[] = []
  let category: string | null = null

  for (const [cat, keywords] of Object.entries(BLACKLIST_CATEGORIES)) {
    for (const keyword of keywords) {
      if (lowerPrompt.includes(keyword.toLowerCase())) {
        violations.push(keyword)
        category = cat
      }
    }
  }

  return {
    passed: violations.length === 0,
    violations,
    category
  }
}
```

**ä½¿ç”¨ç¤ºä¾‹**:

```typescript
const result = checkBlacklist("Generate a video about cute cats")
// { passed: true, violations: [], category: null }

const result2 = checkBlacklist("Create deepfake of president")
// { passed: false, violations: ['deepfake president'], category: 'political' }
```

---

### ç¬¬äºŒå±‚ï¼šAIå†…å®¹åˆ†æï¼ˆGemini 3.0ï¼‰

**ç›®æ ‡**: ç†è§£ä¸Šä¸‹æ–‡ï¼Œæ£€æµ‹éšæ™¦è¿è§„å†…å®¹

#### ä¸ºä»€ä¹ˆéœ€è¦AIå®¡æŸ¥ï¼Ÿ

é»‘åå•æ— æ³•æ£€æµ‹ï¼š
- "åˆ›å»ºä¸€ä¸ªå…³äº'ç‰¹æ®ŠæœåŠ¡'çš„æ¨å¹¿è§†é¢‘"ï¼ˆéšæ™¦è‰²æƒ…ï¼‰
- "ç”ŸæˆæŸä½å…¬ä¼—äººç‰©è¯´è¯çš„è§†é¢‘"ï¼ˆDeepfakeæ„å›¾ï¼‰
- "åˆ¶ä½œä¸€ä¸ª'æ•™è‚²æ€§'çš„æš´åŠ›æ¼”ç¤º"ï¼ˆä¼ªè£…çš„æš´åŠ›å†…å®¹ï¼‰

#### å®ç°æ–¹æ¡ˆ

```typescript
// src/lib/moderation/ai-moderation.ts
import { GoogleGenerativeAI } from '@google/generative-ai'

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY!)

export async function aiContentModeration(prompt: string): Promise<{
  passed: boolean
  riskScore: number // 0-100
  reasoning: string
  categories: string[]
}> {
  const model = genAI.getGenerativeModel({ 
    model: "gemini-1.5-flash"
  })

  const moderationPrompt = `
ä½ æ˜¯ä¸€ä¸ªå†…å®¹å®¡æŸ¥AIã€‚åˆ†æä»¥ä¸‹è§†é¢‘ç”ŸæˆPromptï¼Œåˆ¤æ–­æ˜¯å¦è¿åå†…å®¹æ”¿ç­–ã€‚

ã€å®¡æŸ¥ç»´åº¦ã€‘
1. è‰²æƒ…/æ€§æš—ç¤ºå†…å®¹
2. æš´åŠ›/è¡€è…¥å†…å®¹
3. ä»‡æ¨è¨€è®º/æ­§è§†
4. æ”¿æ²»äººç‰©Deepfake
5. åäººDeepfake
6. è™šå‡ä¿¡æ¯/è¯¯å¯¼
7. éæ³•æ´»åŠ¨ï¼ˆæ¯’å“/æ­¦å™¨ï¼‰
8. ä¾µæƒå†…å®¹

ã€ç”¨æˆ·Promptã€‘
"${prompt}"

ã€è¾“å‡ºæ ¼å¼ã€‘ï¼ˆä¸¥æ ¼JSONï¼‰
{
  "passed": true/false,
  "riskScore": 0-100,
  "reasoning": "è¯¦ç»†è§£é‡Š",
  "categories": ["è¿è§„ç±»å‹1", "è¿è§„ç±»å‹2"]
}

ã€åˆ¤æ–­æ ‡å‡†ã€‘
- riskScore > 70: ç›´æ¥æ‹’ç»
- riskScore 40-70: äººå·¥å¤å®¡
- riskScore < 40: é€šè¿‡

è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—ã€‚
`

  try {
    const result = await model.generateContent(moderationPrompt)
    const text = result.response.text()
    
    // æå–JSONï¼ˆç§»é™¤markdownä»£ç å—æ ‡è®°ï¼‰
    const jsonMatch = text.match(/\{[\s\S]*\}/)
    if (!jsonMatch) {
      throw new Error('AIè¿”å›æ ¼å¼é”™è¯¯')
    }
    
    const analysis = JSON.parse(jsonMatch[0])
    
    return {
      passed: analysis.passed && analysis.riskScore < 70,
      riskScore: analysis.riskScore,
      reasoning: analysis.reasoning,
      categories: analysis.categories || []
    }
  } catch (error) {
    // Fail-Closed: å®¡æŸ¥å¤±è´¥æ—¶æ‹’ç»è¯·æ±‚
    console.error('AIå®¡æŸ¥å¤±è´¥:', error)
    return {
      passed: false,
      riskScore: 100,
      reasoning: 'AIå®¡æŸ¥æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œä¸ºå®‰å…¨èµ·è§æ‹’ç»è¯·æ±‚',
      categories: ['system_error']
    }
  }
}
```

#### æµ‹è¯•ç”¨ä¾‹

```typescript
// æµ‹è¯•æ¡ˆä¾‹1: æ­£å¸¸å†…å®¹
await aiContentModeration("Generate a video about cooking pasta")
// { passed: true, riskScore: 5, reasoning: "æ­£å¸¸çƒ¹é¥ªæ•™å­¦å†…å®¹", categories: [] }

// æµ‹è¯•æ¡ˆä¾‹2: éšæ™¦è‰²æƒ…
await aiContentModeration("Create promotional video for massage parlor with special services")
// { passed: false, riskScore: 85, reasoning: "Special servicesæš—ç¤ºæ€§æœåŠ¡", categories: ["sexual"] }

// æµ‹è¯•æ¡ˆä¾‹3: Deepfakeæ„å›¾
await aiContentModeration("Generate video of Biden saying he will resign")
// { passed: false, riskScore: 95, reasoning: "æ¶‰åŠæ”¿æ²»äººç‰©è™šå‡è¨€è®º", categories: ["political", "deepfake"] }
```

---

### ç¬¬ä¸‰å±‚ï¼šç”¨æˆ·é£é™©è¯„åˆ†

**ç›®æ ‡**: ç›‘æ§ç”¨æˆ·è¡Œä¸ºï¼Œè¯†åˆ«æ¶æ„è´¦å·

#### é£é™©è¯„åˆ†ç®—æ³•

```typescript
// src/lib/moderation/user-risk.ts
export interface UserRiskProfile {
  userId: string
  riskScore: number // 0-100
  violations: {
    total: number
    recent30Days: number
    categories: Record<string, number>
  }
  accountAge: number // å¤©æ•°
  generatedVideos: number
  approvalRate: number // é€šè¿‡ç‡
}

export async function calculateUserRisk(userId: string): Promise<UserRiskProfile> {
  const [violations, account, videos] = await Promise.all([
    getViolationHistory(userId),
    getUserAccount(userId),
    getUserVideos(userId)
  ])

  const accountAgeDays = (Date.now() - account.createdAt.getTime()) / (1000 * 60 * 60 * 24)
  const approvalRate = videos.approved / videos.total

  let riskScore = 0

  // 1. è¿è§„å†å²ï¼ˆæœ€é«˜50åˆ†ï¼‰
  riskScore += Math.min(violations.recent30Days * 10, 50)

  // 2. è´¦å·æ–°æ—§ï¼ˆæœ€é«˜20åˆ†ï¼‰
  if (accountAgeDays < 7) riskScore += 20
  else if (accountAgeDays < 30) riskScore += 10

  // 3. é€šè¿‡ç‡ï¼ˆæœ€é«˜30åˆ†ï¼‰
  if (approvalRate < 0.5) riskScore += 30
  else if (approvalRate < 0.7) riskScore += 15

  return {
    userId,
    riskScore: Math.min(riskScore, 100),
    violations: {
      total: violations.total,
      recent30Days: violations.recent30Days,
      categories: violations.categories
    },
    accountAge: accountAgeDays,
    generatedVideos: videos.total,
    approvalRate
  }
}

// é£é™©ç­‰çº§åˆ¤å®š
export function getRiskLevel(score: number): 'low' | 'medium' | 'high' | 'critical' {
  if (score < 30) return 'low'
  if (score < 60) return 'medium'
  if (score < 80) return 'high'
  return 'critical'
}

// é™æµç­–ç•¥
export function getRateLimits(riskLevel: string): {
  dailyVideos: number
  requireManualReview: boolean
} {
  switch (riskLevel) {
    case 'low':
      return { dailyVideos: 50, requireManualReview: false }
    case 'medium':
      return { dailyVideos: 20, requireManualReview: false }
    case 'high':
      return { dailyVideos: 5, requireManualReview: true }
    case 'critical':
      return { dailyVideos: 0, requireManualReview: true } // å°ç¦
    default:
      return { dailyVideos: 10, requireManualReview: true }
  }
}
```

---

## æŠ€æœ¯å®ç°

### å®Œæ•´å®¡æŸ¥æµç¨‹

```typescript
// src/app/api/videos/generate/route.ts
import { checkBlacklist } from '@/lib/moderation/blacklist'
import { aiContentModeration } from '@/lib/moderation/ai-moderation'
import { calculateUserRisk, getRiskLevel, getRateLimits } from '@/lib/moderation/user-risk'

export async function POST(request: Request) {
  const { userId, prompt } = await request.json()

  // ç¬¬ä¸€å±‚ï¼šé»‘åå•å¿«é€Ÿè¿‡æ»¤
  const blacklistResult = checkBlacklist(prompt)
  if (!blacklistResult.passed) {
    await logViolation(userId, 'blacklist', blacklistResult)
    return Response.json({
      error: 'æ‚¨çš„è¯·æ±‚åŒ…å«è¿è§„å†…å®¹',
      details: `è¿è§„ç±»å‹: ${blacklistResult.category}`,
      code: 'BLACKLIST_VIOLATION'
    }, { status: 400 })
  }

  // ç¬¬äºŒå±‚ï¼šAIå†…å®¹åˆ†æ
  const aiResult = await aiContentModeration(prompt)
  if (!aiResult.passed) {
    await logViolation(userId, 'ai_moderation', aiResult)
    return Response.json({
      error: 'å†…å®¹å®¡æŸ¥æœªé€šè¿‡',
      details: aiResult.reasoning,
      riskScore: aiResult.riskScore,
      code: 'AI_MODERATION_FAILED'
    }, { status: 400 })
  }

  // ç¬¬ä¸‰å±‚ï¼šç”¨æˆ·é£é™©è¯„åˆ†
  const userRisk = await calculateUserRisk(userId)
  const riskLevel = getRiskLevel(userRisk.riskScore)
  const limits = getRateLimits(riskLevel)

  if (limits.dailyVideos === 0) {
    return Response.json({
      error: 'æ‚¨çš„è´¦å·å·²è¢«æš‚åœ',
      details: 'å¤šæ¬¡è¿è§„ï¼Œè¯·è”ç³»å®¢æœ',
      code: 'ACCOUNT_SUSPENDED'
    }, { status: 403 })
  }

  if (limits.requireManualReview) {
    // æäº¤äººå·¥å¤å®¡é˜Ÿåˆ—
    await submitForReview(userId, prompt, { blacklistResult, aiResult, userRisk })
    return Response.json({
      status: 'pending_review',
      message: 'æ‚¨çš„è¯·æ±‚å·²æäº¤äººå·¥å®¡æ ¸',
      estimatedTime: '2-4å°æ—¶'
    })
  }

  // é€šè¿‡æ‰€æœ‰å®¡æŸ¥ï¼Œå¼€å§‹ç”Ÿæˆ
  const videoJob = await startVideoGeneration(userId, prompt)
  
  return Response.json({
    status: 'processing',
    jobId: videoJob.id
  })
}

// è®°å½•è¿è§„
async function logViolation(
  userId: string,
  layer: 'blacklist' | 'ai_moderation' | 'user_risk',
  details: any
) {
  await supabase.from('moderation_logs').insert({
    user_id: userId,
    layer,
    details,
    created_at: new Date().toISOString()
  })
}
```

---

## æ•°æ®åº“Schema

```sql
-- å®¡æŸ¥æ—¥å¿—è¡¨
CREATE TABLE moderation_logs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID NOT NULL REFERENCES auth.users(id),
  layer TEXT NOT NULL, -- 'blacklist' | 'ai_moderation' | 'user_risk'
  prompt TEXT NOT NULL,
  passed BOOLEAN NOT NULL,
  details JSONB NOT NULL,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- è¿è§„è®°å½•è¡¨
CREATE TABLE user_violations (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID NOT NULL REFERENCES auth.users(id),
  violation_type TEXT NOT NULL,
  severity TEXT NOT NULL, -- 'low' | 'medium' | 'high' | 'critical'
  details JSONB NOT NULL,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- ç”¨æˆ·é£é™©æ¡£æ¡ˆè¡¨
CREATE TABLE user_risk_profiles (
  user_id UUID PRIMARY KEY REFERENCES auth.users(id),
  risk_score INTEGER NOT NULL DEFAULT 0,
  risk_level TEXT NOT NULL DEFAULT 'low',
  total_violations INTEGER NOT NULL DEFAULT 0,
  recent_violations INTEGER NOT NULL DEFAULT 0,
  account_status TEXT NOT NULL DEFAULT 'active', -- 'active' | 'warning' | 'suspended'
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- ç´¢å¼•ä¼˜åŒ–
CREATE INDEX idx_moderation_logs_user ON moderation_logs(user_id, created_at DESC);
CREATE INDEX idx_violations_user ON user_violations(user_id, created_at DESC);
CREATE INDEX idx_risk_level ON user_risk_profiles(risk_level);
```

---

## ç›‘æ§ä¸å‘Šè­¦

### Supabaseå®æ—¶ç›‘æ§

```typescript
// å®æ—¶ç›‘æ§é«˜é£é™©ç”¨æˆ·
const subscription = supabase
  .channel('high-risk-alerts')
  .on(
    'postgres_changes',
    {
      event: 'INSERT',
      schema: 'public',
      table: 'user_violations',
      filter: 'severity=eq.critical'
    },
    (payload) => {
      // å‘é€å‘Šè­¦åˆ°Discord/Slack
      sendAlert({
        title: 'ğŸš¨ ä¸¥é‡è¿è§„è­¦æŠ¥',
        userId: payload.new.user_id,
        details: payload.new.details,
        timestamp: new Date().toISOString()
      })
    }
  )
  .subscribe()
```

### è‡ªåŠ¨åŒ–å¤„ç†

```sql
-- è‡ªåŠ¨å°ç¦ç´¯è®¡è¿è§„ç”¨æˆ·
CREATE OR REPLACE FUNCTION auto_suspend_violators()
RETURNS void AS $$
BEGIN
  UPDATE user_risk_profiles
  SET 
    account_status = 'suspended',
    updated_at = NOW()
  WHERE 
    total_violations >= 5 
    OR recent_violations >= 3
    OR risk_score >= 90;
END;
$$ LANGUAGE plpgsql;

-- å®šæ—¶ä»»åŠ¡ï¼ˆæ¯å°æ—¶æ‰§è¡Œï¼‰
SELECT cron.schedule('auto-suspend', '0 * * * *', 'SELECT auto_suspend_violators()');
```

---

## æˆæœ¬åˆ†æ

### Gemini AIå®¡æŸ¥æˆæœ¬

```
å‡è®¾ï¼š
- æ¯ä¸ªPromptå¹³å‡200 tokensï¼ˆè¾“å…¥ï¼‰ + 100 tokensï¼ˆè¾“å‡ºï¼‰
- Gemini 1.5 Flashå®šä»·: $0.075/1M tokens (è¾“å…¥), $0.30/1M tokens (è¾“å‡º)

å•æ¬¡å®¡æŸ¥æˆæœ¬ = (200 Ã— 0.075 + 100 Ã— 0.30) / 1,000,000
            = 0.000045 USD
            â‰ˆ $0.00005 (0.005ç¾åˆ†)

æœˆåº¦10ä¸‡æ¬¡å®¡æŸ¥ = $5
æœˆåº¦100ä¸‡æ¬¡å®¡æŸ¥ = $50
```

**ç»“è®º**: AIå®¡æŸ¥æˆæœ¬æä½ï¼Œå®Œå…¨å¯æ‰¿å—

---

## æµ‹è¯•ç”¨ä¾‹

```typescript
describe('Content Moderation', () => {
  test('é»‘åå•æ£€æµ‹ - æ˜æ˜¾è¿è§„', async () => {
    const result = checkBlacklist('Generate porn video')
    expect(result.passed).toBe(false)
    expect(result.category).toBe('sexual')
  })

  test('AIå®¡æŸ¥ - éšæ™¦å†…å®¹', async () => {
    const result = await aiContentModeration(
      'Create video promoting special massage services'
    )
    expect(result.passed).toBe(false)
    expect(result.riskScore).toBeGreaterThan(70)
  })

  test('ç”¨æˆ·é£é™© - æ–°è´¦å·é™åˆ¶', async () => {
    const risk = await calculateUserRisk('new-user-id')
    expect(risk.riskScore).toBeGreaterThan(20)
  })

  test('å®Œæ•´æµç¨‹ - æ­£å¸¸å†…å®¹', async () => {
    const response = await POST({
      userId: 'test-user',
      prompt: 'Generate video about cooking'
    })
    expect(response.status).toBe(200)
  })
})
```

---

## æ€»ç»“

### é˜²æŠ¤æ•ˆæœ

| å±‚çº§ | æ‹¦æˆªç›®æ ‡ | å‡†ç¡®ç‡ | å“åº”æ—¶é—´ |
|------|----------|--------|----------|
| é»‘åå• | æ˜æ˜¾è¿è§„ | 95% | <10ms |
| AIå®¡æŸ¥ | éšæ™¦å†…å®¹ | 90% | 200-500ms |
| ç”¨æˆ·é£é™© | æ¶æ„è´¦å· | 85% | <50ms |
| **æ•´ä½“** | **ç»¼åˆé˜²æŠ¤** | **98%+** | **<1ç§’** |

### å…³é”®æŒ‡æ ‡

- âœ… **è¯¯æ‹¦æˆªç‡**: <2%ï¼ˆæ­£å¸¸å†…å®¹è¢«é”™è¯¯æ‹’ç»ï¼‰
- âœ… **æ¼æŠ¥ç‡**: <1%ï¼ˆè¿è§„å†…å®¹é€šè¿‡å®¡æŸ¥ï¼‰
- âœ… **å®¡æŸ¥æˆæœ¬**: $0.00005/æ¬¡
- âœ… **å“åº”æ—¶é—´**: <1ç§’

---

**æ–‡æ¡£ç‰ˆæœ¬**: v2.0  
**æœ€åæ›´æ–°**: 2024-11-19  
**ç»´æŠ¤è€…**: Jilo.ai Security Team